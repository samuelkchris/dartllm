// ignore_for_file: always_specify_types
// ignore_for_file: camel_case_types
// ignore_for_file: non_constant_identifier_names
// ignore_for_file: unused_element
// ignore_for_file: unused_field

/// Auto-generated FFI bindings for DartLLM.
///
/// These bindings are generated from native/src/dartllm.h using ffigen.
/// To regenerate: dart run ffigen --config ffigen.yaml

// AUTO GENERATED FILE, DO NOT EDIT.
//
// Generated by `package:ffigen`.
// ignore_for_file: type=lint, unused_import
import 'dart:ffi' as ffi;

/// Auto-generated FFI bindings for DartLLM native library.
class DartLLMBindings {
  /// Holds the symbol lookup function.
  final ffi.Pointer<T> Function<T extends ffi.NativeType>(String symbolName)
  _lookup;

  /// The symbols are looked up in [dynamicLibrary].
  DartLLMBindings(ffi.DynamicLibrary dynamicLibrary)
    : _lookup = dynamicLibrary.lookup;

  /// The symbols are looked up with [lookup].
  DartLLMBindings.fromLookup(
    ffi.Pointer<T> Function<T extends ffi.NativeType>(String symbolName) lookup,
  ) : _lookup = lookup;

  /// Initialize the DartLLM library.
  ///
  /// Must be called once before any other functions. Initializes the llama.cpp
  /// backend, detects available hardware acceleration, and sets up logging.
  ///
  /// @return 0 on success, non-zero error code on failure
  int dartllm_init() {
    return _dartllm_init();
  }

  late final _dartllm_initPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('dartllm_init');
  late final _dartllm_init = _dartllm_initPtr.asFunction<int Function()>();

  /// Get the library version string.
  ///
  /// @return Version string (e.g., "0.1.0"). Do not free.
  ffi.Pointer<ffi.Char> dartllm_version() {
    return _dartllm_version();
  }

  late final _dartllm_versionPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function()>>(
        'dartllm_version',
      );
  late final _dartllm_version = _dartllm_versionPtr
      .asFunction<ffi.Pointer<ffi.Char> Function()>();

  /// Get the llama.cpp backend version.
  ///
  /// @return llama.cpp version string. Do not free.
  ffi.Pointer<ffi.Char> dartllm_llama_version() {
    return _dartllm_llama_version();
  }

  late final _dartllm_llama_versionPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function()>>(
        'dartllm_llama_version',
      );
  late final _dartllm_llama_version = _dartllm_llama_versionPtr
      .asFunction<ffi.Pointer<ffi.Char> Function()>();

  /// Load a model from a GGUF file.
  ///
  /// @param path          Absolute path to the GGUF model file (UTF-8)
  /// @param context_size  Context size in tokens (0 for model default)
  /// @param gpu_layers    Number of layers to offload to GPU (-1 for auto, 0 for CPU-only)
  /// @param threads       Number of CPU threads (0 for auto-detect)
  /// @param batch_size    Batch size for prompt processing (0 for default)
  /// @param use_mmap      Non-zero to memory-map the model file
  ///
  /// @return Opaque model handle, or NULL on failure
  ffi.Pointer<ffi.Void> dartllm_load_model(
    ffi.Pointer<ffi.Char> path,
    int context_size,
    int gpu_layers,
    int threads,
    int batch_size,
    int use_mmap,
  ) {
    return _dartllm_load_model(
      path,
      context_size,
      gpu_layers,
      threads,
      batch_size,
      use_mmap,
    );
  }

  late final _dartllm_load_modelPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
            ffi.Pointer<ffi.Char>,
            ffi.Int32,
            ffi.Int32,
            ffi.Int32,
            ffi.Int32,
            ffi.Int8,
          )
        >
      >('dartllm_load_model');
  late final _dartllm_load_model = _dartllm_load_modelPtr
      .asFunction<
        ffi.Pointer<ffi.Void> Function(
          ffi.Pointer<ffi.Char>,
          int,
          int,
          int,
          int,
          int,
        )
      >();

  /// Unload a model and free all associated resources.
  ///
  /// @param model Model handle from dartllm_load_model()
  void dartllm_free_model(ffi.Pointer<ffi.Void> model) {
    return _dartllm_free_model(model);
  }

  late final _dartllm_free_modelPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>(
        'dartllm_free_model',
      );
  late final _dartllm_free_model = _dartllm_free_modelPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>)>();

  /// Get information about a loaded model.
  ///
  /// @param model Model handle from dartllm_load_model()
  ///
  /// @return Pointer to DartLLMModelInfo, or NULL on failure.
  /// Must be freed with dartllm_free().
  ffi.Pointer<DartLLMModelInfo> dartllm_get_model_info(
    ffi.Pointer<ffi.Void> model,
  ) {
    return _dartllm_get_model_info(model);
  }

  late final _dartllm_get_model_infoPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<DartLLMModelInfo> Function(ffi.Pointer<ffi.Void>)
        >
      >('dartllm_get_model_info');
  late final _dartllm_get_model_info = _dartllm_get_model_infoPtr
      .asFunction<
        ffi.Pointer<DartLLMModelInfo> Function(ffi.Pointer<ffi.Void>)
      >();

  /// Tokenize text to token IDs.
  ///
  /// @param model         Model handle
  /// @param text          Input text (UTF-8, null-terminated)
  /// @param add_special   Non-zero to add BOS/EOS tokens
  /// @param out_length    Output: number of tokens produced
  ///
  /// @return Array of token IDs, or NULL on failure.
  /// Must be freed with dartllm_free().
  ffi.Pointer<ffi.Int32> dartllm_tokenize(
    ffi.Pointer<ffi.Void> model,
    ffi.Pointer<ffi.Char> text,
    int add_special,
    ffi.Pointer<ffi.Int32> out_length,
  ) {
    return _dartllm_tokenize(model, text, add_special, out_length);
  }

  late final _dartllm_tokenizePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<ffi.Int32> Function(
            ffi.Pointer<ffi.Void>,
            ffi.Pointer<ffi.Char>,
            ffi.Int8,
            ffi.Pointer<ffi.Int32>,
          )
        >
      >('dartllm_tokenize');
  late final _dartllm_tokenize = _dartllm_tokenizePtr
      .asFunction<
        ffi.Pointer<ffi.Int32> Function(
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<ffi.Char>,
          int,
          ffi.Pointer<ffi.Int32>,
        )
      >();

  /// Convert token IDs back to text.
  ///
  /// @param model         Model handle
  /// @param tokens        Array of token IDs
  /// @param token_count   Number of tokens
  ///
  /// @return UTF-8 string, or NULL on failure.
  /// Must be freed with dartllm_free().
  ffi.Pointer<ffi.Char> dartllm_detokenize(
    ffi.Pointer<ffi.Void> model,
    ffi.Pointer<ffi.Int32> tokens,
    int token_count,
  ) {
    return _dartllm_detokenize(model, tokens, token_count);
  }

  late final _dartllm_detokenizePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
            ffi.Pointer<ffi.Void>,
            ffi.Pointer<ffi.Int32>,
            ffi.Int32,
          )
        >
      >('dartllm_detokenize');
  late final _dartllm_detokenize = _dartllm_detokenizePtr
      .asFunction<
        ffi.Pointer<ffi.Char> Function(
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<ffi.Int32>,
          int,
        )
      >();

  /// Generate tokens from a prompt.
  ///
  /// @param model             Model handle
  /// @param prompt_tokens     Input token IDs
  /// @param prompt_length     Number of prompt tokens
  /// @param max_tokens        Maximum tokens to generate
  /// @param temperature       Sampling temperature (0.0-2.0)
  /// @param top_p             Nucleus sampling threshold (0.0-1.0)
  /// @param top_k             Top-K sampling limit
  /// @param min_p             Minimum probability threshold
  /// @param repetition_penalty Penalty for repeated tokens (1.0-2.0)
  /// @param seed              Random seed (-1 for random)
  ///
  /// @return Generation result, or NULL on failure.
  /// Must be freed with dartllm_free().
  ffi.Pointer<DartLLMGenerateResult> dartllm_generate(
    ffi.Pointer<ffi.Void> model,
    ffi.Pointer<ffi.Int32> prompt_tokens,
    int prompt_length,
    int max_tokens,
    double temperature,
    double top_p,
    int top_k,
    double min_p,
    double repetition_penalty,
    int seed,
  ) {
    return _dartllm_generate(
      model,
      prompt_tokens,
      prompt_length,
      max_tokens,
      temperature,
      top_p,
      top_k,
      min_p,
      repetition_penalty,
      seed,
    );
  }

  late final _dartllm_generatePtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<DartLLMGenerateResult> Function(
            ffi.Pointer<ffi.Void>,
            ffi.Pointer<ffi.Int32>,
            ffi.Int32,
            ffi.Int32,
            ffi.Float,
            ffi.Float,
            ffi.Int32,
            ffi.Float,
            ffi.Float,
            ffi.Int32,
          )
        >
      >('dartllm_generate');
  late final _dartllm_generate = _dartllm_generatePtr
      .asFunction<
        ffi.Pointer<DartLLMGenerateResult> Function(
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<ffi.Int32>,
          int,
          int,
          double,
          double,
          int,
          double,
          double,
          int,
        )
      >();

  /// Generate tokens with streaming callback.
  ///
  /// Calls the callback for each generated token. Generation continues
  /// until max_tokens is reached, a stop token is hit, or the callback
  /// returns zero.
  ///
  /// @param model             Model handle
  /// @param prompt_tokens     Input token IDs
  /// @param prompt_length     Number of prompt tokens
  /// @param max_tokens        Maximum tokens to generate
  /// @param temperature       Sampling temperature (0.0-2.0)
  /// @param top_p             Nucleus sampling threshold (0.0-1.0)
  /// @param top_k             Top-K sampling limit
  /// @param min_p             Minimum probability threshold
  /// @param repetition_penalty Penalty for repeated tokens (1.0-2.0)
  /// @param seed              Random seed (-1 for random)
  /// @param callback          Streaming callback function
  /// @param user_data         User context passed to callback
  ///
  /// @return 0 on success, non-zero error code on failure
  int dartllm_generate_stream(
    ffi.Pointer<ffi.Void> model,
    ffi.Pointer<ffi.Int32> prompt_tokens,
    int prompt_length,
    int max_tokens,
    double temperature,
    double top_p,
    int top_k,
    double min_p,
    double repetition_penalty,
    int seed,
    DartLLMStreamCallback callback,
    ffi.Pointer<ffi.Void> user_data,
  ) {
    return _dartllm_generate_stream(
      model,
      prompt_tokens,
      prompt_length,
      max_tokens,
      temperature,
      top_p,
      top_k,
      min_p,
      repetition_penalty,
      seed,
      callback,
      user_data,
    );
  }

  late final _dartllm_generate_streamPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Int32 Function(
            ffi.Pointer<ffi.Void>,
            ffi.Pointer<ffi.Int32>,
            ffi.Int32,
            ffi.Int32,
            ffi.Float,
            ffi.Float,
            ffi.Int32,
            ffi.Float,
            ffi.Float,
            ffi.Int32,
            DartLLMStreamCallback,
            ffi.Pointer<ffi.Void>,
          )
        >
      >('dartllm_generate_stream');
  late final _dartllm_generate_stream = _dartllm_generate_streamPtr
      .asFunction<
        int Function(
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<ffi.Int32>,
          int,
          int,
          double,
          double,
          int,
          double,
          double,
          int,
          DartLLMStreamCallback,
          ffi.Pointer<ffi.Void>,
        )
      >();

  /// Generate embeddings for tokens.
  ///
  /// @param model         Model handle
  /// @param tokens        Input token IDs
  /// @param token_count   Number of tokens
  /// @param normalize     Non-zero to L2-normalize the output
  /// @param out_dimension Output: embedding dimension
  ///
  /// @return Array of floats (embedding vector), or NULL on failure.
  /// Must be freed with dartllm_free().
  ffi.Pointer<ffi.Float> dartllm_embed(
    ffi.Pointer<ffi.Void> model,
    ffi.Pointer<ffi.Int32> tokens,
    int token_count,
    int normalize,
    ffi.Pointer<ffi.Int32> out_dimension,
  ) {
    return _dartllm_embed(model, tokens, token_count, normalize, out_dimension);
  }

  late final _dartllm_embedPtr =
      _lookup<
        ffi.NativeFunction<
          ffi.Pointer<ffi.Float> Function(
            ffi.Pointer<ffi.Void>,
            ffi.Pointer<ffi.Int32>,
            ffi.Int32,
            ffi.Int8,
            ffi.Pointer<ffi.Int32>,
          )
        >
      >('dartllm_embed');
  late final _dartllm_embed = _dartllm_embedPtr
      .asFunction<
        ffi.Pointer<ffi.Float> Function(
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<ffi.Int32>,
          int,
          int,
          ffi.Pointer<ffi.Int32>,
        )
      >();

  /// Check if GPU acceleration is available.
  ///
  /// @return Non-zero if GPU is available
  int dartllm_has_gpu_support() {
    return _dartllm_has_gpu_support();
  }

  late final _dartllm_has_gpu_supportPtr =
      _lookup<ffi.NativeFunction<ffi.Int8 Function()>>(
        'dartllm_has_gpu_support',
      );
  late final _dartllm_has_gpu_support = _dartllm_has_gpu_supportPtr
      .asFunction<int Function()>();

  /// Get the name of the active GPU backend.
  ///
  /// @return Backend name ("metal", "cuda", "vulkan", "cpu"). Do not free.
  ffi.Pointer<ffi.Char> dartllm_gpu_backend_name() {
    return _dartllm_gpu_backend_name();
  }

  late final _dartllm_gpu_backend_namePtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function()>>(
        'dartllm_gpu_backend_name',
      );
  late final _dartllm_gpu_backend_name = _dartllm_gpu_backend_namePtr
      .asFunction<ffi.Pointer<ffi.Char> Function()>();

  /// Get available VRAM in bytes.
  ///
  /// @return VRAM size, or 0 if GPU not available
  int dartllm_get_vram_size() {
    return _dartllm_get_vram_size();
  }

  late final _dartllm_get_vram_sizePtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function()>>(
        'dartllm_get_vram_size',
      );
  late final _dartllm_get_vram_size = _dartllm_get_vram_sizePtr
      .asFunction<int Function()>();

  /// Free memory allocated by DartLLM functions.
  ///
  /// @param ptr Pointer returned by dartllm_* functions
  void dartllm_free(ffi.Pointer<ffi.Void> ptr) {
    return _dartllm_free(ptr);
  }

  late final _dartllm_freePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>(
        'dartllm_free',
      );
  late final _dartllm_free = _dartllm_freePtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>)>();

  /// Get the last error message.
  ///
  /// @return Error message string, or NULL if no error. Do not free.
  ffi.Pointer<ffi.Char> dartllm_get_last_error() {
    return _dartllm_get_last_error();
  }

  late final _dartllm_get_last_errorPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function()>>(
        'dartllm_get_last_error',
      );
  late final _dartllm_get_last_error = _dartllm_get_last_errorPtr
      .asFunction<ffi.Pointer<ffi.Char> Function()>();

  /// Clear the last error.
  void dartllm_clear_error() {
    return _dartllm_clear_error();
  }

  late final _dartllm_clear_errorPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('dartllm_clear_error');
  late final _dartllm_clear_error = _dartllm_clear_errorPtr
      .asFunction<void Function()>();
}

/// mbstate_t is an opaque object to keep conversion state, during multibyte
/// stream conversions.  The content must not be referenced by user programs.
final class __mbstate_t extends ffi.Union {
  @ffi.Array.multi([128])
  external ffi.Array<ffi.Char> __mbstate8;

  /// for alignment
  @ffi.LongLong()
  external int _mbstateL;
}

/// Model information structure.
///
/// Returned by dartllm_get_model_info(). All strings are null-terminated.
/// The structure uses fixed-size arrays for ABI stability.
final class DartLLMModelInfo extends ffi.Struct {
  /// Model name from GGUF metadata (max 255 chars + null)
  @ffi.Array.multi([256])
  external ffi.Array<ffi.Char> name;

  /// Total parameter count
  @ffi.Int64()
  external int parameter_count;

  /// Architecture name (e.g., "llama", "mistral")
  @ffi.Array.multi([64])
  external ffi.Array<ffi.Char> architecture;

  /// Quantization format (e.g., "Q4_K_M", "Q8_0")
  @ffi.Array.multi([32])
  external ffi.Array<ffi.Char> quantization;

  /// Maximum context size in tokens
  @ffi.Int32()
  external int context_size;

  /// Vocabulary size
  @ffi.Int32()
  external int vocabulary_size;

  /// Embedding dimension
  @ffi.Int32()
  external int embedding_size;

  /// Number of transformer layers
  @ffi.Int32()
  external int layer_count;

  /// Number of attention heads
  @ffi.Int32()
  external int head_count;

  /// Model file size in bytes
  @ffi.Int64()
  external int file_size_bytes;

  /// Non-zero if model supports embedding generation
  @ffi.Int8()
  external int supports_embedding;

  /// Non-zero if model supports vision/multimodal
  @ffi.Int8()
  external int supports_vision;

  /// Chat template from GGUF metadata (may be empty)
  @ffi.Array.multi([4096])
  external ffi.Array<ffi.Char> chat_template;
}

/// Generation result structure.
///
/// Returned by dartllm_generate(). Contains generated tokens and metadata.
/// Variable-length tokens array follows the fixed fields.
final class DartLLMGenerateResult extends ffi.Opaque {}

/// Callback function type for streaming token generation.
///
/// @param token     Generated token ID
/// @param text      Token text (UTF-8, null-terminated)
/// @param is_final  Non-zero if this is the last token
/// @param finish_reason  0=stop, 1=length, 2=error (only valid when is_final)
/// @param user_data User-provided context pointer
///
/// @return Non-zero to continue generation, zero to abort
typedef DartLLMStreamCallback =
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Int32 Function(
          ffi.Int32 token,
          ffi.Pointer<ffi.Char> text,
          ffi.Int8 is_final,
          ffi.Int32 finish_reason,
          ffi.Pointer<ffi.Void> user_data,
        )
      >
    >;
