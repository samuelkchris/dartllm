## 0.1.0

- Initial release
- Core inference engine with llama.cpp backend
- Chat and text completion APIs
- Real-time streaming generation
- Embedding generation
- HuggingFace model downloading
- Platform support: Android, iOS, macOS, Windows, Linux, Web
- GPU acceleration: Metal, CUDA, Vulkan
- 10+ chat template formats (ChatML, Llama2, Llama3, Mistral, Phi3, etc.)
